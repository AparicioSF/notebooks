{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7b2208",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [3]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7ab77",
   "metadata": {
    "papermill": {
     "duration": 0.074274,
     "end_time": "2022-10-22T04:37:05.230693",
     "exception": false,
     "start_time": "2022-10-22T04:37:05.156419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from eoxhub import check_compatibility\n",
    "check_compatibility(\"user-2022.10-14\", dependencies=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a615556-b62f-4392-a82e-9746d300e708",
   "metadata": {
    "papermill": {
     "duration": 0.005372,
     "end_time": "2022-10-22T04:37:05.241843",
     "exception": false,
     "start_time": "2022-10-22T04:37:05.236471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Crop-classification using Sentinel-2 time-series\n",
    "\n",
    "This notebook implements a crop classification algorithm for Sentinel-2 time-series based on deep learning. The input time-series are derived from the signals computed by the Eurocrops BYOA. The method here implemented is described in more detail in the [crop-classification marker blog-post](https://medium.com/sentinel-hub/area-monitoring-crop-type-marker-1e70f672bf44).\n",
    "\n",
    "For more examples on how to create markers for monitoring agricultural activity using Sentinel-2 signals, consult [this blog series](https://medium.com/sentinel-hub/area-monitoring-concept-effc2c262583).\n",
    "\n",
    "This notebook will use a sample of pre-downloaded signals, and can be run on a CPU-based instance or laptop.\n",
    "\n",
    "**Table of Contents**:\n",
    "\n",
    " 0. [Constants](#constants)\n",
    " 1. [Retrieve signals and labels](#retrieve-signals)\n",
    " 2. [AI-ready dataset](#dataset)\n",
    " 3. [Model training](#model-training)\n",
    " 4. [Model evaluation](#model-evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36298b14-3b51-4455-9bda-f6dfbe45e947",
   "metadata": {
    "papermill": {
     "duration": 0.027379,
     "end_time": "2022-10-22T04:37:05.274274",
     "exception": false,
     "start_time": "2022-10-22T04:37:05.246895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['EDC_PATH'] + \"/notebooks/contributions/eurocrops-model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2452c954",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22868cd-049e-4e60-b668-df242d18976e",
   "metadata": {
    "papermill": {
     "duration": 1.050673,
     "end_time": "2022-10-22T04:37:06.330087",
     "exception": true,
     "start_time": "2022-10-22T04:37:05.279414",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from model.lstm import LSTM\n",
    "from model.polygon import PolyDataset\n",
    "from model.transforms import get_sample_n_timestamps\n",
    "from model.utils import test, train\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sentinelhub import parse_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed6baf1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 0. Constants <a name=constants></a>\n",
    "\n",
    "This section initialises paths, constants and utility functions used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff171f7-d27b-4150-9fff-65ef5f456aba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path to local folders, change as desired\n",
    "INPUT_FOLDER = \"./input\"\n",
    "RESULTS_FOLDER = \"./output\"\n",
    "\n",
    "# name of files and folders of downloaded signals, do not change\n",
    "DATAFILE = \"ml-example-data.zip\"\n",
    "DOWNLOAD_URL = f\"https://sinergise0-my.sharepoint.com/:u:/g/personal/nejc_vesel_sinergise_com/ETMx7NG-JHpBntNMJfnsCOMBVuEegDjYq8WtTmJYl8tZ-A?e=Ck5opE&download=1\"\n",
    "EUROCROPS_GPKG = \"input_geometries.gpkg\"\n",
    "SIGNALS_FOLDER = \"ml-example-signals\"\n",
    "\n",
    "\n",
    "# utility function to read json payload into a dataframe\n",
    "def stats_to_df(stats_data):\n",
    "    \"\"\"Transform Statistical API response into a pandas.DataFrame\"\"\"\n",
    "    df_data = []\n",
    "\n",
    "    for single_data in stats_data[\"data\"]:\n",
    "        df_entry = {}\n",
    "        is_valid_entry = True\n",
    "\n",
    "        df_entry[\"interval_from\"] = parse_time(single_data[\"interval\"][\"from\"]).date()\n",
    "        df_entry[\"interval_to\"] = parse_time(single_data[\"interval\"][\"to\"]).date()\n",
    "\n",
    "        for output_name, output_data in single_data[\"outputs\"].items():\n",
    "            for band_name, band_values in output_data[\"bands\"].items():\n",
    "                band_stats = band_values[\"stats\"]\n",
    "                if band_stats[\"sampleCount\"] == band_stats[\"noDataCount\"]:\n",
    "                    is_valid_entry = False\n",
    "                    break\n",
    "\n",
    "                for stat_name, value in band_stats.items():\n",
    "                    col_name = f\"{output_name}_{band_name}_{stat_name}\"\n",
    "                    if stat_name == \"percentiles\":\n",
    "                        for perc, perc_val in value.items():\n",
    "                            perc_col_name = f\"{col_name}_{perc}\"\n",
    "                            df_entry[perc_col_name] = perc_val\n",
    "                    else:\n",
    "                        df_entry[col_name] = value\n",
    "\n",
    "        if is_valid_entry:\n",
    "            df_data.append(df_entry)\n",
    "\n",
    "    return pd.DataFrame(df_data)\n",
    "\n",
    "\n",
    "# utility function to log training progress\n",
    "def define_logger(logger_name) -> logging.Logger:\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\"[%(asctime)s] {%(filename)s:%(lineno)d} %(levelname)s - %(message)s\")\n",
    "\n",
    "    stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "    stdout_handler.setFormatter(formatter)\n",
    "    logger.addHandler(stdout_handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2bdfad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 1. Retrieve signals and labels <a name=retrieve-signals></a>\n",
    "\n",
    "In this Section, signals are read from JSON files, while the labels used during model training are extracted from the Eurocrops dataset. For this notebook, sample files are provided and downloaded locally in the following cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9801c0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(INPUT_FOLDER):\n",
    "    os.mkdir(INPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb2e4bb-f12a-44d4-b251-4ff7a6d39d0f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wget_str = f\"wget {DOWNLOAD_URL} -O {os.path.join(INPUT_FOLDER, DATAFILE)}\"\n",
    "subprocess.call(wget_str.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb779b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unzip files\n",
    "with zipfile.ZipFile(os.path.join(INPUT_FOLDER, DATAFILE), \"r\") as zip_ref:\n",
    "    zip_ref.extractall(INPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac7a66",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls {INPUT_FOLDER}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cfdb78",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Read signals from JSON files as returned by Statistical API and create a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a76b4-d7de-4f41-a373-cf1627e6a77a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for result_json in os.listdir(os.path.join(INPUT_FOLDER, \"ml-example-signals\")):\n",
    "    with open(os.path.join(INPUT_FOLDER, \"ml-example-signals\", result_json)) as f:\n",
    "        result = json.load(f)\n",
    "\n",
    "    result_df = stats_to_df(result[\"response\"])\n",
    "    result_df[\"identifier\"] = int(result[\"identifier\"])\n",
    "    dfs.append(result_df)\n",
    "\n",
    "signals = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da514cc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Check size of dataset and one time observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c9d9b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1fe9cf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "signals.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97033027-af60-48d6-833c-674407b503aa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Read labels from provided geopackage file. These labels can be directly retrieved from GeoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553487e1-a87a-4188-9440-44afcce73fdd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eurocrops_gdf = gpd.read_file(os.path.join(INPUT_FOLDER, EUROCROPS_GPKG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49d47b7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Merge signals and crop labels into a single dataframe, by looking at the identifier of the field of interest (FOI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063c9e9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eurocrops_signals = pd.merge(eurocrops_gdf, signals, on=\"identifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9feeb3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eurocrops_signals.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae235877",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 2. AI-ready dataset <a name=dataset></a>\n",
    "\n",
    "This Section adds some features to be added to the raw bands which will be used by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159580ae-6aec-4ecf-bb02-0d195b75a35d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add column for cloud probability\n",
    "eurocrops_signals[\"CLP\"] = eurocrops_signals[\"clp_B0_mean\"] / 255\n",
    "# compute NDVI\n",
    "eurocrops_signals[\"NDVI\"] = (eurocrops_signals[\"bands_B7_mean\"] - eurocrops_signals[\"bands_B3_mean\"]) / (\n",
    "    eurocrops_signals[\"bands_B7_mean\"] + eurocrops_signals[\"bands_B3_mean\"]\n",
    ")\n",
    "# compute day-of-year from timestamp\n",
    "eurocrops_signals[\"DOY\"] = eurocrops_signals.interval_from.apply(lambda x: x.timetuple().tm_yday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4011f68-c1f3-4538-a69c-195583412d56",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get name of columns to be used as features, i.e. mean values of raw bands\n",
    "feature_cols = [x for x in eurocrops_signals.columns if x.startswith(\"bands_\") and x.endswith(\"_mean\")]\n",
    "# name of utility features\n",
    "doy_feature = \"DOY\"\n",
    "crop_type_feature = \"ec_hcat_c\"\n",
    "crop_name_feature = \"ec_hcat_n\"\n",
    "label_feature = \"label\"\n",
    "identifier_feature = \"identifier\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc82601",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Map all the possible crop-types to specific groups assigned in Eurocrops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f58085-8c34-4fbc-903e-b0e288ecd1ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "crop_id_to_label_mapping = {val: idx for idx, val in enumerate(eurocrops_signals[crop_type_feature].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f0fb5-ae9b-4fb6-96e5-83ee541767c3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "crop_id_to_name_mapping = {\n",
    "    crop_id: crop_name\n",
    "    for crop_id, crop_name in eurocrops_signals[[crop_type_feature, crop_name_feature]].drop_duplicates().values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e62c85-77f7-4398-a6b3-47a7b9065cc3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eurocrops_signals[label_feature] = eurocrops_signals[crop_type_feature].map(crop_id_to_label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ee569",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Split the signals into a training and validation set. This datasets are demonstrative only, as in reality, a larger dataset would be required, and more robust validation strategies required to robustly estimate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e14fa-8bd9-4f85-8cf8-2a583503df5b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ids, val_ids = train_test_split(\n",
    "    eurocrops_signals[identifier_feature].unique(), train_size=0.6, test_size=0.4, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef588253-0165-4ce7-90d7-b8174ad747c7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = eurocrops_signals[eurocrops_signals[identifier_feature].isin(train_ids)]\n",
    "val_df = eurocrops_signals[eurocrops_signals[identifier_feature].isin(val_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be9692",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Create the training and validation datasets to be used for model training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee42057-7193-4ceb-9c82-aaef0fe9146e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_poly_dataset = PolyDataset(\n",
    "    train_df,\n",
    "    feature_cols=feature_cols,\n",
    "    label_col=label_feature,\n",
    "    poly_id_col=identifier_feature,\n",
    "    doys_col=doy_feature,\n",
    "    online_transform=get_sample_n_timestamps(40),\n",
    ")\n",
    "\n",
    "val_poly_dataset = PolyDataset(\n",
    "    val_df,\n",
    "    feature_cols=feature_cols,\n",
    "    label_col=label_feature,\n",
    "    poly_id_col=identifier_feature,\n",
    "    doys_col=doy_feature,\n",
    "    online_transform=get_sample_n_timestamps(40),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f77110",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3. Model training <a name=model-training></a>\n",
    "\n",
    "In this Section, a LSTM model is trained on the signals for estimation of crop-type. The parameters of the LSTM might need tuning to different use-cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4703803c-8913-4986-b629-bceca97c7f0e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "N_WORKERS = 4\n",
    "SHUFFLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d538682-39d2-44fc-ba13-09cd00882845",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_poly_dataset, batch_size=BATCH_SIZE, num_workers=N_WORKERS, shuffle=SHUFFLE)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_poly_dataset, batch_size=BATCH_SIZE, num_workers=N_WORKERS, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08880b5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Initialise the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c10f6-e322-4f8c-a8c9-d0a32146cd86",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm = LSTM(\n",
    "    input_dim=len(feature_cols),\n",
    "    n_classes=eurocrops_signals[label_feature].nunique(),\n",
    "    hidden_dims=128,\n",
    "    num_rnn_layers=3,\n",
    "    dropout=0.2,\n",
    "    bidirectional=True,\n",
    "    use_batchnorm=False,\n",
    "    use_layernorm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c138216",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Initialise the optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b93f9-df20-444a-b155-f4795824c3a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(\n",
    "    filter(lambda x: x.requires_grad, lstm.parameters()),\n",
    "    betas=(0.9, 0.98),\n",
    "    eps=1e-09,\n",
    "    lr=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23dc1d1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Initialise the logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab3732-eedb-4659-872f-b2540f562013",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = define_logger(\"Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc6508",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Train the model !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d4508-18f0-4474-a041-0e485e9fec21",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm = train(lstm, optimizer, train_loader, val_loader, 30, verbose=False, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27791c5a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4. Model evaluation <a name=model-evaluation></a>\n",
    "\n",
    "This Section evaluates the performance of the trained model on the validation dataset. Perfomance is displayed as a confusion matrix, where estimated and reference crop-types are compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba600cea-3134-4f44-b0e8-fdbbacb830c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb79354-2a4a-4249-86b1-7f8c638ee989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=90)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = np.nanmax(cm) / 1.5 if normalize else np.nanmax(cm) / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.2f}; misclass={:0.2f}'.format(accuracy, misclass))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5edda-9132-48e3-97d8-1e83f8bd9397",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions, targets, polygon_ids, logprobabilities = test(lstm, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13404427-32cf-4eb1-99cc-9852862c71a8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(targets, predictions, labels=list(crop_id_to_label_mapping.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b8146-5986-4e54-9c8b-e549b8aad220",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, target_names=[crop_id_to_name_mapping[x] for x in crop_id_to_label_mapping.keys()])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2880452117879b878aa515f032d494a3ad190d8310d205bde4fb9215fd3620a0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.662311,
   "end_time": "2022-10-22T04:37:06.752094",
   "environment_variables": {},
   "exception": true,
   "input_path": "/tmp/tmpdk4r4hav",
   "output_path": "/tmp/notebook_output.ipynb",
   "parameters": {},
   "start_time": "2022-10-22T04:37:04.089783",
   "version": "2.3.4"
  },
  "properties": {
   "authors": [
    {
     "id": "f0a99622-4b85-4610-8669-c73e560d096b",
     "name": "eoresearch@sinergise.com"
    }
   ],
   "description": "Crop classification algorithm for Sentinel-2 time-series.",
   "id": "b5d6fe35-1f1f-495d-ace4-56f55adaf71a",
   "license": null,
   "name": "Crop-classification using Sentinel-2 time-series",
   "requirements": [],
   "tags": [
    "Sentinel Data",
    "Sentinel Hub",
    "Machine Learning",
    "EO Data",
    "Crop-type-Classification"
   ],
   "tosAgree": true,
   "type": "Jupyter Notebook",
   "version": "0.0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
